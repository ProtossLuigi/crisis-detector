{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proto/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/proto/anaconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple, Iterable, Any\n",
    "from warnings import warn\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import lightning as pl\n",
    "from transformers import AutoTokenizer, RobertaModel\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'crisis_data'\n",
    "FILE_BLACKLIST = [\n",
    "    'crisis_data/Jan Szyszko_Córka leśniczego.xlsx',\n",
    "    'crisis_data/Komenda Główna Policji.xlsx',\n",
    "    'crisis_data/Ministerstwo Zdrowia_respiratory od handlarza bronią.xlsx',\n",
    "    'crisis_data/Polska Grupa Energetyczna.xlsx',\n",
    "    'crisis_data/Polski Związek Kolarski.xlsx',\n",
    "    'crisis_data/Zbój_energetyk.xlsx'\n",
    "]\n",
    "\n",
    "crisis = pd.read_excel('crisis_data/Daty_kryzysów.xlsx').dropna()\n",
    "crisis = crisis[~crisis['Plik'].apply(lambda x: os.path.join(DATA_DIR, x) in FILE_BLACKLIST)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_date_range(index: pd.DatetimeIndex, crisis_start: pd.Timestamp) -> pd.DatetimeIndex:\n",
    "    return pd.date_range(max(index.min(), crisis_start - pd.Timedelta(days=60)), min(index.max(), crisis_start + pd.Timedelta(days=29)))\n",
    "\n",
    "def extract_data(filename: str, crisis_start: pd.Timestamp, num_samples: int = 100) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    src_df = pd.read_excel(filename)\n",
    "    \n",
    "    new_cols = ['brak', 'negatywny', 'neutralny', 'pozytywny']\n",
    "    new_cols_ex = [c for c in new_cols if c in src_df['Wydźwięk'].unique().tolist()]\n",
    "    src_df[new_cols_ex] = pd.get_dummies(src_df['Wydźwięk'])\n",
    "    for col in new_cols:\n",
    "        if col not in src_df.columns:\n",
    "            src_df[col] = 0\n",
    "\n",
    "    df = src_df[['Data wydania'] + new_cols].groupby(['Data wydania']).sum()\n",
    "\n",
    "    df = df.reindex(clip_date_range(df.index, crisis_start))\n",
    "    df[new_cols] = df[new_cols].fillna(0)\n",
    "\n",
    "    df['suma'] = df[new_cols].sum(axis=1)\n",
    "    df['labels'] = df.index >= crisis_start\n",
    "    if np.unique(df['labels']).shape[0] != 2:\n",
    "        warn(f'Samples from only 1 class in {filename}.')\n",
    "    if df.shape[0] == 0:\n",
    "        warn(f'No data after clipping for {filename}.')\n",
    "\n",
    "    text = src_df.apply(lambda x: \".\".join([str(x['Tytuł publikacji']), str(x['Lead']), str(x['Kontekst publikacji'])]), axis=1)\n",
    "    text_df = src_df[['Data wydania']].copy()\n",
    "    text_df['text'] = text\n",
    "    texts = []\n",
    "    for date in df.index:\n",
    "        daily_posts = text_df[text_df['Data wydania'] == date]\n",
    "        texts.append(daily_posts if daily_posts.shape[0] <= num_samples else daily_posts.sample(n=num_samples))\n",
    "    text_df = pd.concat(texts).reset_index(drop=True)\n",
    "    \n",
    "    return df, text_df\n",
    "\n",
    "def load_data(filenames: Iterable[str], crisis_dates: Iterable[pd.Timestamp], num_samples: int = 100) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    assert len(filenames) == len(crisis_dates)\n",
    "    dfs, text_dfs = [], []\n",
    "    for i, (fname, date) in enumerate(tqdm(zip(filenames, crisis_dates), total=len(filenames))):\n",
    "        df, text_df = extract_data(fname, date, num_samples)\n",
    "        df = df.reset_index(names='Data wydania')\n",
    "        df['group'] = i\n",
    "        text_df['group'] = i\n",
    "        dfs.append(df)\n",
    "        text_dfs.append(text_df)\n",
    "    return pd.concat(dfs, ignore_index=True), pd.concat(text_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictDataset(Dataset):\n",
    "    def __init__(self, items: dict) -> None:\n",
    "        super().__init__()\n",
    "        self.items = items\n",
    "        self.len = len(self.items[list(self.items.keys())[0]])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return {key: val[index] for key, val in self.items.items()}\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.len\n",
    "\n",
    "class SeriesDataset(Dataset):\n",
    "    def __init__(self, series: pd.Series) -> None:\n",
    "        super().__init__()\n",
    "        self.series = series\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.series.iloc[index]\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.series.shape[0]\n",
    "    \n",
    "class TextVectorizer(pl.LightningModule):\n",
    "    def __init__(self, pretrained_name: str, max_length: int = 256, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.model = RobertaModel.from_pretrained(pretrained_name)\n",
    "        self.model._modules['pooler'] = torch.nn.Identity()\n",
    "    \n",
    "    def forward(self, x) -> Any:\n",
    "        return self.model(**x).pooler_output.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embeddings(days_df: pd.DataFrame, text_df: pd.DataFrame, embeddings: List[torch.Tensor] | torch.Tensor) -> pd.DataFrame:\n",
    "    if type(embeddings) == list:\n",
    "        embeddings = torch.cat(embeddings, dim=0)\n",
    "    embeddings = embeddings.numpy()\n",
    "    sections = np.cumsum(text_df.groupby(['group', 'Data wydania']).count()['text']).tolist()[:-1]\n",
    "    day_embeddings = np.stack([np.mean(t, axis=0) for t in np.vsplit(embeddings, sections)], axis=0)\n",
    "    embedding_df = text_df[['group', 'Data wydania']].drop_duplicates().reset_index(drop=True)\n",
    "    embedding_df['embedding'] = day_embeddings.tolist()\n",
    "    days_df = days_df.join(day_embeddings.set_index(['group', 'Data wydania']), ['group', 'Data wydania'], how='left')\n",
    "    days_df.loc[:, 'embedding'].iloc[days_df['embedding'].isna()] = pd.Series(np.zeros((days_df['embedding'].isna().sum(), 768)).tolist())\n",
    "    return days_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df: pd.DataFrame) -> Dataset:\n",
    "    sentiment_cols = ['brak', 'pozytywny', 'neutralny', 'negatywny']\n",
    "    X = torch.tensor(df[sentiment_cols])\n",
    "    y = torch.tensor(df['label'], dtype=torch.long)\n",
    "    embeddings = torch.tensor(df['embedding'])\n",
    "    groups = df['group'].to_list()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, text_df = load_data(crisis['Plik'].apply(lambda x: os.path.join(DATA_DIR, x)).to_list(), crisis['Data'].to_list())\n",
    "# df.to_feather('other_data/days_df.feather')\n",
    "# text_df.to_feather('other_data/posts_df.feather')\n",
    "\n",
    "days_df = pd.read_feather('other_data/days_df.feather')\n",
    "text_df = pd.read_feather('other_data/posts_df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_LENGTH = 256\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"sdadas/polish-distilroberta\")\n",
    "# tokens  = tokenizer(text_df['text'].to_list(), truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sdadas/polish-distilroberta were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at sdadas/polish-distilroberta and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/proto/anaconda3/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9b07bf6e7a4ce59a065277e3b87fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sdadas/polish-distilroberta')\n",
    "ds = SeriesDataset(text_df['text'])\n",
    "collate_fn = lambda x: tokenizer(x, truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
    "dl = DataLoader(ds, 256, num_workers=10, collate_fn=collate_fn, pin_memory=True)\n",
    "model = TextVectorizer('sdadas/polish-distilroberta')\n",
    "trainer = pl.Trainer(accelerator='gpu')\n",
    "embeddings = trainer.predict(model, dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_embeddings = aggregate_embeddings(embeddings, text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5975/258083745.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  days_df.loc[:, 'embedding'].iloc[days_df['embedding'].isna()] = pd.Series(np.zeros((days_df['embedding'].isna().sum(), 768)).tolist())\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data wydania</th>\n",
       "      <th>brak</th>\n",
       "      <th>negatywny</th>\n",
       "      <th>neutralny</th>\n",
       "      <th>pozytywny</th>\n",
       "      <th>suma</th>\n",
       "      <th>labels</th>\n",
       "      <th>group</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.023331861943006516, 0.16732020676136017, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.023742012679576874, 0.12002455443143845, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.02524435520172119, 0.14957286417484283, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.01904178224503994, 0.1732526421546936, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1157.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1301.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.005615352187305689, 0.15572427213191986, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6945</th>\n",
       "      <td>2015-09-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6946</th>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6947</th>\n",
       "      <td>2015-09-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6948</th>\n",
       "      <td>2015-09-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6949</th>\n",
       "      <td>2015-09-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "      <td>[-0.02471078932285309, 0.11491697281599045, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6950 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data wydania  brak  negatywny  neutralny  pozytywny    suma  labels  \\\n",
       "0      2022-11-06   0.0        2.0      150.0       26.0   178.0   False   \n",
       "1      2022-11-07   0.0        2.0      137.0      122.0   261.0   False   \n",
       "2      2022-11-08   0.0        0.0       35.0       19.0    54.0   False   \n",
       "3      2022-11-09   0.0        8.0      136.0       12.0   156.0   False   \n",
       "4      2022-11-10   0.0       22.0     1157.0      122.0  1301.0   False   \n",
       "...           ...   ...        ...        ...        ...     ...     ...   \n",
       "6945   2015-09-12   0.0        0.0        0.0        0.0     0.0    True   \n",
       "6946   2015-09-13   0.0        0.0        0.0        0.0     0.0    True   \n",
       "6947   2015-09-14   0.0        0.0        0.0        0.0     0.0    True   \n",
       "6948   2015-09-15   0.0        0.0        0.0        0.0     0.0    True   \n",
       "6949   2015-09-16   0.0        0.0        1.0        0.0     1.0    True   \n",
       "\n",
       "      group                                          embedding  \n",
       "0         0  [0.023331861943006516, 0.16732020676136017, 0....  \n",
       "1         0  [0.023742012679576874, 0.12002455443143845, 0....  \n",
       "2         0  [0.02524435520172119, 0.14957286417484283, 0.0...  \n",
       "3         0  [0.01904178224503994, 0.1732526421546936, 0.02...  \n",
       "4         0  [0.005615352187305689, 0.15572427213191986, 0....  \n",
       "...     ...                                                ...  \n",
       "6945     77  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6946     77  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6947     77  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6948     77  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6949     77  [-0.02471078932285309, 0.11491697281599045, 0....  \n",
       "\n",
       "[6950 rows x 9 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6950, 768])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(days_df['embedding']).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
