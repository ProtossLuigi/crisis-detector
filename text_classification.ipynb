{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import datasets\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'crisis_data'\n",
    "FILE_BLACKLIST = [\n",
    "    'crisis_data/Afera Rywina.xlsx',\n",
    "    'crisis_data/Ministerstwo Zdrowia_respiratory od handlarza bronią.xlsx',\n",
    "    'crisis_data/Fake news_baza publikacji.xlsx'\n",
    "]\n",
    "\n",
    "files = [os.path.join(DATA_DIR, f) for f in os.listdir(DATA_DIR) if f[-5:] == '.xlsx']\n",
    "for f in FILE_BLACKLIST:\n",
    "    files.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(filenames: List[str]):\n",
    "    dss = []\n",
    "    for filename in filenames:\n",
    "        df = pd.read_excel(filename)\n",
    "        df = df[['Kryzys', 'Tytuł publikacji', 'Lead', 'Kontekst publikacji']]\n",
    "        df['text'] = df.apply(lambda x: \".\".join([x['Tytuł publikacji'], x['Lead'], x['Kontekst publikacji']]), axis=1)\n",
    "        df = df[['Kryzys', 'text']]\n",
    "        dss.append(datasets.Dataset.from_pandas(df))\n",
    "    return datasets.concatenate_datasets(dss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 1: expected str instance, float found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prepare_dataset(files)\n",
      "Cell \u001b[0;32mIn[33], line 6\u001b[0m, in \u001b[0;36mprepare_dataset\u001b[0;34m(filenames)\u001b[0m\n\u001b[1;32m      4\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(filename)\n\u001b[1;32m      5\u001b[0m df \u001b[39m=\u001b[39m df[[\u001b[39m'\u001b[39m\u001b[39mKryzys\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTytuł publikacji\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLead\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mKontekst publikacji\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m----> 6\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: \u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin([x[\u001b[39m'\u001b[39;49m\u001b[39mTytuł publikacji\u001b[39;49m\u001b[39m'\u001b[39;49m], x[\u001b[39m'\u001b[39;49m\u001b[39mLead\u001b[39;49m\u001b[39m'\u001b[39;49m], x[\u001b[39m'\u001b[39;49m\u001b[39mKontekst publikacji\u001b[39;49m\u001b[39m'\u001b[39;49m]]), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m df \u001b[39m=\u001b[39m df[[\u001b[39m'\u001b[39m\u001b[39mKryzys\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m      8\u001b[0m dss\u001b[39m.\u001b[39mappend(datasets\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_pandas(df))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9557\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9559\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    893\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    905\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    911\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[33], line 6\u001b[0m, in \u001b[0;36mprepare_dataset.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(filename)\n\u001b[1;32m      5\u001b[0m df \u001b[39m=\u001b[39m df[[\u001b[39m'\u001b[39m\u001b[39mKryzys\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTytuł publikacji\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLead\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mKontekst publikacji\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m----> 6\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin([x[\u001b[39m'\u001b[39;49m\u001b[39mTytuł publikacji\u001b[39;49m\u001b[39m'\u001b[39;49m], x[\u001b[39m'\u001b[39;49m\u001b[39mLead\u001b[39;49m\u001b[39m'\u001b[39;49m], x[\u001b[39m'\u001b[39;49m\u001b[39mKontekst publikacji\u001b[39;49m\u001b[39m'\u001b[39;49m]]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m df \u001b[39m=\u001b[39m df[[\u001b[39m'\u001b[39m\u001b[39mKryzys\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m      8\u001b[0m dss\u001b[39m.\u001b[39mappend(datasets\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_pandas(df))\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 1: expected str instance, float found"
     ]
    }
   ],
   "source": [
    "prepare_dataset(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1847699c2fc40838f1fe3ab9142a688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/341 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fed15185794a9a827fdbeabf1a0d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/3.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac3a03e904f4dca8578d110b5031fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sdadas/polish-distilroberta\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_train = small_train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test = small_test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id nowe', 'Id stare', 'Kryzys', 'Tytuł publikacji', 'Źródło', 'Autor',\n",
       "       'Data wydania', 'Data i godzina dodania', 'Strona (prasa)',\n",
       "       'Godzina publikacji (Radio, TV, Social media)', 'Czas trwania (RTV)',\n",
       "       'Folder', 'Projekt', 'Rodzaj projektu', 'Udział', 'Rozmiar', 'Wydźwięk',\n",
       "       'Ave szacunkowe (PLN)', 'Ave zweryfikowane (PLN)', 'Ave mnożone (PLN)',\n",
       "       'Dotarcie (kontaktów)',\n",
       "       'Zasięg (egz.), (słuchaczy), (widzów), (UU), (subskrybentów), (obserwujących)',\n",
       "       'Wpływ', 'Typ medium', 'Tematyka', 'Social media - typ wpisu',\n",
       "       'Czestotliwość (prasa)', 'Wydawca', 'Kraj', 'Obszar',\n",
       "       'Obszar - szczegóły', 'Powierzchnia gazety', 'Id medium',\n",
       "       'Podgrupa medium', 'Powierzchnia (Prasa, Internet)', 'Status',\n",
       "       'Komunikaty', 'Tagi', 'Lead', 'Kontekst publikacji',\n",
       "       'Język publikacji (ISO)', 'Link do publikacji',\n",
       "       'Link źródłowy (internet)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Tytuł publikacji'].apply(lambda x: tokenizer(x, truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [input_ids, attention_mask]\n",
       "1      [input_ids, attention_mask]\n",
       "2      [input_ids, attention_mask]\n",
       "3      [input_ids, attention_mask]\n",
       "4      [input_ids, attention_mask]\n",
       "                  ...             \n",
       "262    [input_ids, attention_mask]\n",
       "263    [input_ids, attention_mask]\n",
       "264    [input_ids, attention_mask]\n",
       "265    [input_ids, attention_mask]\n",
       "266    [input_ids, attention_mask]\n",
       "Name: Tytuł publikacji, Length: 267, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"sdadas/polish-distilroberta\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
